<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
      <title>Background Process on Background Process </title>
      <generator uri="https://gohugo.io">Hugo</generator>
    <link>http://backgroundprocess.com/</link>
    <language>en-us</language>
    <author>Tim Kuhlman</author>
    
    <updated>Thu, 27 Jun 2019 21:44:01 UTC</updated>
    
    <item>
      <title>DevOps - You Build It, You Run It</title>
      <link>http://backgroundprocess.com/usatodaynetwork/build_and_run/</link>
      <pubDate>Thu, 27 Jun 2019 21:44:01 UTC</pubDate>
      <author>Tim Kuhlman</author>
      <guid>http://backgroundprocess.com/usatodaynetwork/build_and_run/</guid>
      <description>&lt;p&gt;&lt;em&gt;Originally written with help from my team and posted at &lt;a href=&#34;https://medium.com/usa-today-network/devops-you-build-it-you-run-it-8f972343eb8e&#34;&gt;https://medium.com/usa-today-network/devops-you-build-it-you-run-it-8f972343eb8e&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We know DevOps is a paradigm shift for software development. But the wide range of DevOps definitions and processes make it difficult, especially across organizations, to define what DevOps is in practice. Is it a development team working well with an operations team? Or is it a third team connecting the others? The API Services team at USA TODAY NETWORK doesn’t fit either of those scenarios. Our approach can be summed up by the slogan, “You Build It, You Run It.”&lt;/p&gt;

&lt;h2 id=&#34;one-team&#34;&gt;One Team&lt;/h2&gt;

&lt;p&gt;DevOps at its core is about aligning the responsibility for running services with the authority to improve them. The quality and velocity of improvements for a service are greatly improved when responsibility and authority are in alignment. A dev team and an operations team which don’t collaborate are functionally broken, because the day-to-day responsibility rests on the operations team while the authority to make changes belongs to the dev team. One way to solve this is to improve communication between teams while building shared responsibility for running the service, along with shared authority to modify it. The approach we take is similar. We don’t have two teams. A single team both builds the service and runs it. It works well for us!&lt;/p&gt;

&lt;h2 id=&#34;benefits&#34;&gt;Benefits&lt;/h2&gt;

&lt;h3 id=&#34;organizational-benefits&#34;&gt;Organizational Benefits&lt;/h3&gt;

&lt;p&gt;Maintaining a single team with aligned responsibility and authority means we don’t need cross-team communication. Instead, we can rely on much easier intra-team communication. Individual skillsets still vary, but the goals and responsibilities are shared by the team as a whole. Everyone becomes more aligned. Also, cross-team communication is no longer tied up with service level concerns and becomes freed up for discussions regarding composition of services and other higher-level concerns.&lt;/p&gt;

&lt;p&gt;Here are some other reasons we’ve found that “You Build It, You Run It” leads to better services:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Improved issue visibility: A team responsible for running a service is careful to make it run well. (This is true for any DevOps organization, especially when you will be paged for incidents.)&lt;/li&gt;
&lt;li&gt;Reduced issue resolution time: You’re dealing with a single team, so delays caused by cross-team communication disappear and everyone involved understands both the operation and development of the service.&lt;/li&gt;
&lt;li&gt;Immediate feedback loop: The feedback loop for problems is automatic; no need to communicate out the cause of a problem, just immediately fix it. A faster feedback loop equals better service.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;engineer-benefits&#34;&gt;Engineer Benefits&lt;/h3&gt;

&lt;p&gt;Teams can be formed with engineers with various specialties. But whenever practical, we strive for every engineer to learn the skillsets needed for both operations and development. Building a whole team of highly-skilled and trusted engineers is a challenge, but it’s not insurmountable. Engineers like to be both highly-skilled and trusted, so setting this expectation — along with plenty of learning resources — drives growth.&lt;/p&gt;

&lt;p&gt;Engineers embrace this approach because of the resulting skillset growth and job satisfaction opportunities. Here’s why:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Execution is the best teacher. For example, devs learn to better incorporate instrumentation and security into an application when they also run the service.&lt;/li&gt;
&lt;li&gt;You can better build a more effective and relevant product when you see and truly understand the whole picture. It also allows you to make wise tradeoffs on features, development speed, security, etc. In short, you become a better engineer. Understanding the whole is also more satisfying than working on a portion with only limited context.&lt;/li&gt;
&lt;li&gt;Building a service paired with seeing it used — as well as using it yourself — is satisfying.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;beyond-one-team&#34;&gt;Beyond One Team&lt;/h2&gt;

&lt;p&gt;The success we’ve described isn’t possible without a set of robust, well-maintained services to build on. Today’s cloud-native infrastructure allows a single team to run an application that requires a CI system, database, Kubernetes, etc. An engineer can confidently use these services and rarely have to worry about service-specific details, so her time is freed up for other concerns. When details for a dependent service require investigation, the service maintainer can be brought in for assistance. For these reasons, building on top of robust services prevents the amount of work in the system from growing beyond what a single team can handle.&lt;/p&gt;

&lt;p&gt;Even with cloud-native services, nearly every company has plenty of work for multiple teams. Embracing an “as a service” team organization model can help teams divide and conquer along lines that enable each to build and run their own services. If CI for your company is run internally, the team responsible can offer CI as a service. Other teams then consume it as a tool they use when building their own services. This enables both the CI team and teams that use that service to follow the “You Build It, You Run It” model of DevOps.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;We’ve found that “You Build It, You Run It” doesn’t just bridge the fence between development and operations teams, but rather pulls that fence down altogether and embodies the spirit of DevOps. Immediate feedback on changes leads to quick fixes and better services. Working this way enables engineers to become better, grow in their skillset and improve their job satisfaction.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A Culture of Architectural Design</title>
      <link>http://backgroundprocess.com/usatodaynetwork/design_culture/</link>
      <pubDate>Thu, 28 Mar 2019 21:44:01 UTC</pubDate>
      <author>Tim Kuhlman</author>
      <guid>http://backgroundprocess.com/usatodaynetwork/design_culture/</guid>
      <description>&lt;p&gt;&lt;em&gt;Originally written with help from my team and posted at &lt;a href=&#34;https://medium.com/usa-today-network/a-culture-of-architectural-design-77ad815dfc90&#34;&gt;https://medium.com/usa-today-network/a-culture-of-architectural-design-77ad815dfc90&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The API Services team at the USA TODAY NETWORK values well-designed software services with good architecture. Who doesn’t? We seek to achieve this goal by having everyone involved in the architectural design.&lt;/p&gt;

&lt;p&gt;Promoting “design as a culture” — where the entire development team is involved in the architectural design — has some significant advantages:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The team has a better overall understanding of the solution design and is aligned on the project goals. This in turn leads to better and faster development through greater understanding of what needs to be done and ensures smoother communication.&lt;/li&gt;
&lt;li&gt;Everyone involved in the design has skin in the game. Greater ownership of the project increases engagement and job satisfaction.&lt;/li&gt;
&lt;li&gt;Architects enjoy more time to work on development. Experienced developers who are tasked solely with architecture responsibilities can grow stale in their development skills, which ultimately reduces their effectiveness.&lt;/li&gt;
&lt;li&gt;Most engineers find it more satisfying to be involved in both the design and implementation of a project than to only work on one aspect.&lt;/li&gt;
&lt;li&gt;Good ideas can come from anyone. When everyone contributes, the quality and creativity of your solutions increases.&lt;/li&gt;
&lt;li&gt;The team grows in their skill and understanding, making them that more effective for the next project.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After embracing the idea that all developers should be involved in design, the primary disadvantage to this approach becomes clear — it takes more coordination and time to finalize a design.&lt;/p&gt;

&lt;p&gt;The idea of everyone doing design has many parallels with teams doing code reviews. In both you trade some upfront time for other benefits which outweigh that cost. With a larger portion of the team enjoying a better understanding of the project up front, we see overall improvements in velocity and quality which make up for the initial slowdown.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://imgs.xkcd.com/comics/timeline_of_bicycle_design.png&#34; alt=&#34;https://xkcd.com/1673/&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;putting-it-into-practice&#34;&gt;Putting it into Practice&lt;/h2&gt;

&lt;p&gt;Implementing the idea of “software design as a culture” is fairly simple: assign design tasks to various team members. The hard part is mentoring and teaching your entire team good design principles. Here are a few suggestions for how to get started:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Designs must be peer reviewed. Similar to code reviews, architectural designs are most valuable when reviewed.&lt;/li&gt;
&lt;li&gt;Answer these questions: Why is a project being considered as something to spend time on? What is being asked for specifically? How to build the project? This last question is the main design but the why and what questions align priorities, build a common understanding and foundations needed for a quality architecture.&lt;/li&gt;
&lt;li&gt;Projects come in different sizes and so should designs. Sometimes design is skipped for small projects or when there are changes to existing projects, which is generally a mistake. The why, what and how questions should still be answered — but in a size appropriate way.&lt;/li&gt;
&lt;li&gt;Design docs are not just prose, they should often include diagrams. In all cases the design document should be easily reviewable. A common format used by the team can aid in readability.&lt;/li&gt;
&lt;li&gt;Save design docs — They are great for a history of why changes were made and to help on board new team members.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The practice of “software design as a culture” is a shift in thinking that returns many benefits for your team and organization. The change requires a focus on building this skillset for your team but results in better designs with fewer mistakes, greater alignment on work priorities, increased productivity and improved job satisfaction.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Design Docs Best Practices</title>
      <link>http://backgroundprocess.com/design/design_doc/</link>
      <pubDate>Thu, 03 May 2018 10:42:45 MDT</pubDate>
      <author>Tim Kuhlman</author>
      <guid>http://backgroundprocess.com/design/design_doc/</guid>
      <description>&lt;p&gt;Each project deserves careful thought on the design and architecture of the solution. This is something that should be done at the start of projects and for each major revision. One tool for design and architecting is to write a design doc for each major revision.&lt;/p&gt;

&lt;p&gt;The audience for these docs includes the team that will do the implementation but also other technical developers and architects within the organization who can give feedback. Design docs brings these advantages to a project:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The problem to be solved, implementation goals and design decisions with tradeoffs are understood by all involved parties not just the implementors. This also serves to align all interested parties on the primary goals of a project.&lt;/li&gt;
&lt;li&gt;Others can review the design and provide feedback. The is made possible because design docs enable talking about design decisions one step removed from the implementation details allowing for a wider audience to have time to understand and review the process.&lt;/li&gt;
&lt;li&gt;The design doc provides a historic reference on why things were done as they were which can be referenced in the future as the project evolves.&lt;/li&gt;
&lt;li&gt;The design doc provides an intro to a service that allows anyone who will begin working on implementation details an overview that helps them place implementation decisions in the right context and therefore to make the right tradeoff decisions.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;key-sections&#34;&gt;Key Sections&lt;/h3&gt;

&lt;p&gt;Design docs can vary in their scope and layout according to the project but there should be sections that address the why/what/how questions. The key sections that should be covered include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Why&lt;/em&gt; - Project Goals/Problem Description - This section lays out why this project is being worked on, what is the motivation for spending the time on it. As part of this section you may want to include specific use cases that give a concrete picture on how the project is intended to be used.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;What&lt;/em&gt; - Requirements and Implementation Goals - Define the requirements for this project and its constraints whether these are non-negotiable technology decisions (ie must integrate with X) or SLAs that we would like to meet. Sometimes it is quite helpful to detail out what is not in scope for this project to prevent unintentional scope creep.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;How&lt;/em&gt; - Design/Architecture - This is likely the largest section where the primary design decisions are detailed with the reasons for choosing one direction over others that were considered. Where possible include concrete data that led to these design decisions. Also try and cover all the major aspects to a service including the operational characteristics such as monitoring and security as well as the good architecture considerations and practices allow the project to be evolvable in the future.&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Done Criteria</title>
      <link>http://backgroundprocess.com/code/done/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 UTC</pubDate>
      <author>Tim Kuhlman</author>
      <guid>http://backgroundprocess.com/code/done/</guid>
      <description>&lt;p&gt;A checklist list of done criteria is helpful to avoid skipping any steps in code creation, this is the list I use for my projects.
Where possible automated tools should be used to help verify good practices are followed.
These tools are typically language specific so I skipped adding any here.&lt;/p&gt;

&lt;h2 id=&#34;ready-for-review&#34;&gt;Ready for Review&lt;/h2&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; Committed with a good commit message to appropriate branches as determined by the teams source control practices.&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt;  The code works and shows that by being well covered with automated tests, some combination of unit and/or integration tests as appropriate.&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; Quality, including:

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; The code has good style and has been lint checked.&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; Simplicity, the code is easy to read and maintain, avoids complexitiy and is focused on solving a single problem.&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; All errors are handled.&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; Documented - design and implementations documented in or close to the code as needed.&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; Metrics exposed, healthcheck exposed.&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;ready-for-deployment&#34;&gt;Ready for Deployment&lt;/h2&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; Reviewed and merged.&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; Tested in a staging environment.&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; Demoed and approved by product owner.&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;done&#34;&gt;Done&lt;/h2&gt;

&lt;ul class=&#34;task-list&#34;&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; Dashboards for metrics created.&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; Alerts in place.&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; Runbook for alerts created&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; Documented - All relevant user and administration documentation is in place.&lt;/label&gt;&lt;/li&gt;
&lt;li&gt;&lt;label&gt;&lt;input type=&#34;checkbox&#34; disabled class=&#34;task-list-item&#34;&gt; Live&lt;/label&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>A Golang implementation of PasswordSafe V3, ready for Beta</title>
      <link>http://backgroundprocess.com/code/gopwsafe-beta/</link>
      <pubDate>Fri, 27 May 2016 21:43:39 MDT</pubDate>
      <author>Tim Kuhlman</author>
      <guid>http://backgroundprocess.com/code/gopwsafe-beta/</guid>
      <description>&lt;p&gt;The password database I have been implementing in go is ready for Beta! The DB is implemented using the &lt;a href=&#34;http://pwsafe.org/&#34;&gt;password safe&lt;/a&gt; version 3
database spec. Enough of the features for this are now working that
&lt;a href=&#34;https://github.com/tkuhlman/gopwsafe/releases/tag/0.3.0&#34;&gt;0.3.0 release&lt;/a&gt; is ready for others to test.&lt;/p&gt;

&lt;p&gt;I have been using this code for months and would encourage anyone else needing a password DB to check it out now. I have particularly enjoyed the ability
to search across multiple open password dbs at one time. This was the primary itch I was scratching in taking up this project. Though that feature has been
implemented for months the gui it has been missing some basics such as a reminder to save after changes, the ability to change a DB password and to make a
new DB. These features are now all working.&lt;/p&gt;

&lt;p&gt;It is still a beta release because there are many missing features and some known bugs. The primary bug right now is that closing an open DB doesn&amp;rsquo;t work
without closing the entire program. The &lt;a href=&#34;https://github.com/tkuhlman/gopwsafe&#34;&gt;project readme&lt;/a&gt; has a good running list of missing features in the Roadmap
section. Primarily these are features that take advantage of have multiple DBs open at once, such as the ability to move records from one DB to another.
Lastly the gtk gui could use countless tweaks to clean it up.&lt;/p&gt;

&lt;p&gt;If you test it out have any feedback or find any bugs use the &lt;a href=&#34;https://github.com/tkuhlman/gopwsafe/issues&#34;&gt;project issues&lt;/a&gt; section to notify me.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Docker for Messy Pets - Updates</title>
      <link>http://backgroundprocess.com/systems/desktop_docker2/</link>
      <pubDate>Mon, 02 May 2016 21:07:28 MDT</pubDate>
      <author>Tim Kuhlman</author>
      <guid>http://backgroundprocess.com/systems/desktop_docker2/</guid>
      <description>&lt;p&gt;About 8 months ago I posted about how I run some
&lt;a href=&#34;http://backgroundprocess.com/systems/desktop_docker/&#34;&gt;applications in containers&lt;/a&gt;
so that they stay nicely contained. I have refined and changed a few things about how I do this
recently and so felt it was time for an update.&lt;/p&gt;

&lt;p&gt;I do maintain a
&lt;a href=&#34;https://github.com/tkuhlman/containers&#34;&gt;git repo&lt;/a&gt; that will always have the latest I am using but
here is the summary:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;At some point pulseaudio broke for me, possibly after an OS or Docker upgrade. I didn&amp;rsquo;t track
down the cause but rather just decided to setup tcp based pulse audio. This is more initial
setup but should be more stable and is simpler in the startup scripts. Audio works great this
way and the container can play audio but not run configuration commands like pacmd.
To setup:

&lt;ul&gt;
&lt;li&gt;Turn on tcp for pulseaudio, in &lt;code&gt;/etc/pulse/default.pa&lt;/code&gt; add a line like &lt;code&gt;load-module
module-native-protocol-tcp&lt;/code&gt; and restart pulseaudio, &lt;code&gt;pulseaudio -k&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If you are running ufw like me you need a rule like,
&lt;code&gt;ufw allow in on docker0 to my-docker-ip proto tcp port 4713&lt;/code&gt; with the appropriate Docker ip.
This allows Docker containers to reach pulse on port 4713 but should keep everything else out.&lt;/li&gt;
&lt;li&gt;Then in the container startup scripts I have some lines like these used for Docker options:&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code&gt;-v ~/.config/pulse/cookie:/run/pulse/cookie
-e PULSE_SERVER=tcp:$(ifconfig docker0| awk &#39;/inet addr/{print substr($2,6)}&#39;):4713
-e PULSE_COOKIE=/run/pulse/cookie
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;Turns out you don&amp;rsquo;t need &lt;code&gt;xhost local:&lt;/code&gt; in your scripts if I you are sharing &lt;code&gt;/tmp/.X11-unix&lt;/code&gt;
and have $DISPLAY set. I&amp;rsquo;m not sure how I missed this 8 months ago but it is nice to avoid that.&lt;/li&gt;
&lt;li&gt;There is a lot to love about Docker but like many CLI interfaces it could use some work.
I mostly start containers with scripts but I also have a couple of aliases for some common other
tasks:

&lt;ul&gt;
&lt;li&gt;To show current containers both running and not, &lt;code&gt;alias dps=&#39;docker ps -a --format &amp;quot;table
{{.Names}}\t{{.Status}}\t{{.Image}}&amp;quot;&#39;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;To run a command in the container with a terminal, which I often use like &lt;code&gt;dexec container
bash&lt;/code&gt;. The alias is &lt;code&gt;alias dexec=&#39;docker exec -t -i&#39;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Recently I posted about how I use
&lt;a href=&#34;http://backgroundprocess.com/infrastructure/containers-over-vms/&#34;&gt;containers rather than VMs&lt;/a&gt; but
those use cases are just the beginning. As I add applications
to my workstation I can now be conservative on what I install and what install sources I trust on
my workstation and instead use a container to keep unknown software confined.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Containers over VMs</title>
      <link>http://backgroundprocess.com/infrastructure/containers-over-vms/</link>
      <pubDate>Sat, 16 Apr 2016 21:06:14 MDT</pubDate>
      <author>Tim Kuhlman</author>
      <guid>http://backgroundprocess.com/infrastructure/containers-over-vms/</guid>
      <description>&lt;p&gt;I recently realized it has been over 6 months since I have used a VM on my workstation. Previously I
like many developers used VMs for various development tasks. The change hasn&amp;rsquo;t be in my usage of
cloud based VMs, I continue to do that as needed and appropriate. The change is that I use containers.&lt;/p&gt;

&lt;p&gt;I now use a mix of &lt;a href=&#34;https://www.docker.com/&#34;&gt;Docker&lt;/a&gt; and &lt;a href=&#34;https://linuxcontainers.org/lxd/&#34;&gt;LXD&lt;/a&gt; for dev and
test environments and everything else I used to frequently use VMs for on my workstation. I even use containers in some
&lt;a href=&#34;http://backgroundprocess.com/systems/desktop_docker/&#34;&gt;ways&lt;/a&gt; that I haven&amp;rsquo;t used VMs.&lt;/p&gt;

&lt;p&gt;Realizing this change in my behavior is somewhat startling for me, after all VMs represented a paradigm
shift in the industry which certainly affected my workflow years ago. I previously found tools like
&lt;a href=&#34;http://backgroundprocess.com/infrastructure/vagrant/&#34;&gt;Vagrant&lt;/a&gt; a very useful part of my workflow. Nevertheless the advantages to
using containers for tasks on my personal workstation have change my workflow.&lt;/p&gt;

&lt;p&gt;Containers come with nearly all the workflow advantages that VMs do but also with additional advantages
beyond VMs:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Speed of execution - I have various aliases and scripts that launch containerized applications
and speed of startup and execution is indistinguishable from native apps.&lt;/li&gt;
&lt;li&gt;Lightweight - Not only are containers much faster than VMs they are light on resource usage so
much so that you can have many running and not notice it. I actually use signficantly less memory on my
machine than I did a year ago.&lt;/li&gt;
&lt;li&gt;Easier to share - Though possible with VMs it is just simply quicker and easier to share Docker containers.&lt;/li&gt;
&lt;li&gt;Quicker and simpler to build - The speed of startup and ease of sharing contribute to it being
really easy to startup a new container makes some changes and save it off for further use. This allows me
to nest usages, repeat test cases on different versions, etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The net effect is that for many uses containers just have less overhead than VMs but retain the primary advantages
that VMs brought to the industry. There are of course reasons to still use VMs on a personal workstation,
such as not running Linux as a primary OS and so lacking container support natively, doing development on the kernel,
or developing for an OS other than Linux. None of these are relevant for me so containers is the way forward on
my machines.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Mojo Integration Tests with LXD</title>
      <link>http://backgroundprocess.com/code/mojo-integration-tests/</link>
      <pubDate>Fri, 12 Feb 2016 13:36:07 MST</pubDate>
      <author>Tim Kuhlman</author>
      <guid>http://backgroundprocess.com/code/mojo-integration-tests/</guid>
      <description>&lt;p&gt;I have recently finished building an LXD image for doing integration tests of &lt;a href=&#34;https://mojo.canonical.com&#34;&gt;Mojo&lt;/a&gt;.
I did this because I wanted to be able to reliably test the changes to Mojo that I was making. A repeatable,
standard environment that can run set of integration tests fits the bill.&lt;/p&gt;

&lt;h2 id=&#34;using-a-container&#34;&gt;Using a Container&lt;/h2&gt;

&lt;p&gt;There are a few key advantages I see to doing the integration tests in a container image like this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Having a repeatable environment enables automation, sharing of the environment among developers, using
the environment as a base standard and incremental improvement.&lt;/li&gt;
&lt;li&gt;The image can be built to a standard, in this case it runs Ubuntu LTS with the latest distributed versions
of Juju/Mojo and other tooling.&lt;/li&gt;
&lt;li&gt;Isolation from the primary dev environment allows for easy cleanup, easier testing of various branches and tests
more easily run in parallel.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;integration-tests&#34;&gt;Integration Tests&lt;/h2&gt;

&lt;p&gt;Integration tests themselves I want running because some tests are just not practical to do via
unit tests. This is especially true for code that interacts with a lot of other programs such as Mojo.&lt;/p&gt;

&lt;p&gt;In many cases integration tests bring an real world element unit tests don&amp;rsquo;t. For example the Mojo unit tests
cover Juju interactions decently well using the expected Juju status output. However what if that
expected output changes? For example Juju output could change in a way that is harmless and not
noticed so everyone upgrades Juju, then later Mojo changes but the unit tests are all based on the
older output, integration tests will catch this before sending broken code to production.&lt;/p&gt;

&lt;p&gt;On the other hand some tests, ie proper parsing of a manifest file, work better as a unit test. In other
situations it perhaps isn&amp;rsquo;t so clear. Have integration tests as a tool in addition to unit tests gives Mojo
developers another way to validate code before merging.&lt;/p&gt;

&lt;h2 id=&#34;more-information&#34;&gt;More Information&lt;/h2&gt;

&lt;p&gt;The image can also be used for development of Mojo specs, there is some information on that and more information on using the image in the
image &lt;a href=&#34;http://bazaar.launchpad.net/~mojo-maintainers/mojo/trunk/view/head:/contrib/LXD/README.md&#34;&gt;readme&lt;/a&gt;.
I also made this &lt;a href=&#34;https://youtu.be/Q8ll7OsTtMk&#34;&gt;screen cast&lt;/a&gt; to introduce how I use the image today. I often watch
these screen casts at double speed and recommend you do for this one also.&lt;/p&gt;

&lt;p&gt;Now that the base image is done all the Mojo developers can all incrementally add more tests and I look forward to seeing it expand.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Weechat Command Queues</title>
      <link>http://backgroundprocess.com/code/weechat-queue/</link>
      <pubDate>Mon, 01 Feb 2016 21:39:58 MST</pubDate>
      <author>Tim Kuhlman</author>
      <guid>http://backgroundprocess.com/code/weechat-queue/</guid>
      <description>&lt;p&gt;I use &lt;a href=&#34;http://weechat.org&#34;&gt;weechat&lt;/a&gt; for much of the day and have issue regular repetitive commands periodically.
If you are in the same situation you may find the &lt;a href=&#34;https://weechat.org/scripts/source/queue.py.html/&#34;&gt;queue plugin&lt;/a&gt; I recently modified to be useful.&lt;/p&gt;

&lt;p&gt;The queue plugin simply allows you to build up a list of commands then run them all at once. My
&lt;a href=&#34;https://github.com/weechat/scripts/pull/137/files&#34;&gt;modification&lt;/a&gt; was to allow saving these across restarts of weechat.
That way I can build up a few queues I use regularily and just call them whenever needed.&lt;/p&gt;

&lt;p&gt;For example when I start my day I just execute &lt;code&gt;/qu exec morning&lt;/code&gt; to switch my away status, announce my availability in a couple of rooms, etc.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Development Best Practices for Systems Administrators</title>
      <link>http://backgroundprocess.com/code/sysadmins/</link>
      <pubDate>Sat, 16 Jan 2016 20:44:55 MST</pubDate>
      <author>Tim Kuhlman</author>
      <guid>http://backgroundprocess.com/code/sysadmins/</guid>
      <description>&lt;p&gt;The days where systems administrators do no development are gone. Just as developers
leverage cloud infrastructure and tooling to deploy services, sysadmins develop code to automate
their infrastructure and to fill the feature gaps that they are uniquely positioned to see.&lt;/p&gt;

&lt;p&gt;Though best development practices are the same for both sysadmins and devs, some are more
natural to one group or another. The heart of devops is operators and developers coming together and in many ways this
post is really about what sysadmins can learn from developers. Here are some best practices I think come less naturally to operators.&lt;/p&gt;

&lt;h2 id=&#34;best-practices&#34;&gt;Best Practices&lt;/h2&gt;

&lt;h3 id=&#34;simplify&#34;&gt;Simplify&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Interface&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Make your project simple to use. Sysadmins are badasses at the CLI and forget not everyone is. Also make sure to keep the interface consistent.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Standardize&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Choose sane defaults, don&amp;rsquo;t be afraid to limit choice and flexibility so the code steers people toward good and/or standard practices.
Choice can be good at times but more often than not is a bit stifling. One difference between a usable project and a great one is often in appropriate
defaults and simplicity of configuration.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Code Structure&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Turns out the basics of code are easy, children can grasp the concepts of branches and loops. Most code is dealing with the complexity
of having so many branches and loops. That is why the common code constructs (classes, inheritance, types/interfaces) exist.
Layers of abstraction, separation of concern and encapsulation are amount the keys to good complexity management. The difference between
good design and bad is how well the complexity management is done.&lt;/p&gt;

&lt;p&gt;There are many code techniques to deal with complexity and this is a great example of where sysadmins can learn a lot from devs. I&amp;rsquo;ll not delve
into actual techniques but rather here are some principles to keep in mind while coding:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://sysadvent.blogspot.com/2015/12/day-22-simplicity-in-complex-systems.html&#34;&gt;Reducing code complexity&lt;/a&gt; by thinking about where the code can shrink
or hide the complexity. Shrink complexity by building code constructs that break the complexity up. Hide it by building complexity into
methods or objects, hiding it from the rest of the system.&lt;/li&gt;
&lt;li&gt;Keep your code organized. One principle to avoid sprawling code is, &lt;a href=&#34;http://martinfowler.com/bliki/Yagni.html&#34;&gt;YAGNI&lt;/a&gt;, only write to what you
actually need now. Sysadmins run systems and so have great insight into what is needed making this best practice relatively easy. However there
is one caution with YAGNI. To quote Martin Fowler &amp;ldquo;Yagni only applies to capabilities built into the software to support a presumptive feature, it does
not apply to effort to make the software easier to modify.&amp;rdquo; In short YAGNI is not an excuse for unorganized code. Organize your code and revisit the
organization to keep it organized as it grows and more features are added.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;document&#34;&gt;Document&lt;/h3&gt;

&lt;p&gt;Document your code! Maybe this is one both devs and sysadmins could do better at.&lt;/p&gt;

&lt;p&gt;Document as you are writing the code. After having just written the code you know what it does and there is no better time to clearly express that.
The code&amp;rsquo;s lifecycle is just beginning, the project will be used and modified by yourself and others and good documentation helps immensely with
these further steps.&lt;/p&gt;

&lt;p&gt;The closer to the code the documentation is the better. It is most likely to stay up date if the documentation is close to the code as well as being the
easiest to find. Also being close to the code gives you an automatic context allowing the documentation to be more succinct.
Most languages have built-in tools for documenting well and publishing the docs in a standard way, use these tools.&lt;/p&gt;

&lt;p&gt;In addition to helping with the further lifecycle of your project the act of documenting is a tool for discovering unnecessarily complexity.
When documenting you have to force yourself to think like someone unfamiliar with the project which is an important mindset to adopt periodically.
This is especially true when writing the overview section of your docs which links project components together into a whole that users will interact with.
I often find documenting reveals big wins where just a bit more code results in a large improvements.&lt;/p&gt;

&lt;h3 id=&#34;test&#34;&gt;Test&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Automated Testing&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I find sysadmins often test manually really well but don&amp;rsquo;t automate the testing as well. The manual testing is great that first
time but the automated testing provides repeatability. The repeatability is key for proving functionality and for any future changes, which
for most projects are bound to happen.&lt;/p&gt;

&lt;p&gt;Automated testing does have its limits, in particular unit testing is limited in how useful it can be for code that interacts with other
systems. This is the type of code sysadmins write most often. It is difficult and fragile to mock out code that does network I/O, a system call, db I/O and
more network I/O. This doesn&amp;rsquo;t mean skip automated tests but rather ensure the use cases are covered with
automated integration tests. A great use of containers is to create pre-built test environments for automate integration testing.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Real World Usage&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Use and run your own code in a real environment. It is through running code in a real environment that you discover the true
problems that need fixing. Indeed the motivation for much of the code sysadmins write comes from running real environments. Even though this seems
obvious to sysadmins it is a key best practices that is so important it needs to be mentioned.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Launchpad Merge Proposal Helper Script</title>
      <link>http://backgroundprocess.com/code/mp/</link>
      <pubDate>Fri, 01 Jan 2016 12:20:22 MST</pubDate>
      <author>Tim Kuhlman</author>
      <guid>http://backgroundprocess.com/code/mp/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve written a script to aid in merge proposals done with &lt;a href=&#34;https://launchpad.net/&#34;&gt;Launchpad&lt;/a&gt;.
Simply run the command with the url of the merge proposal as the argument and the script will&lt;/p&gt;

&lt;p&gt;spawn a shell with the working directory being the code with the uncommitted
merge. You can then diff the code, run tests or whatever else as needed.&lt;/p&gt;

&lt;p&gt;When you exit the shell you will be prompted to merge, if you choose to do so a commit message will be
populated for you and opened in an editor so you can edit as you choose. This is also your 2nd
opportunity to bail if you need to. Assuming all is good save and the merge will be done.&lt;/p&gt;

&lt;p&gt;The script leverages your installed credentials for bzr and will use
&lt;a href=&#34;https://help.launchpad.net/API/launchpadlib&#34;&gt;launchpadlib&lt;/a&gt; to authenticate
against the api on your first usage.&lt;/p&gt;

&lt;p&gt;The script is at &lt;a href=&#34;https://github.com/tkuhlman/scripts/blob/master/bin/mp&#34;&gt;https://github.com/tkuhlman/scripts/blob/master/bin/mp&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If you use &lt;a href=&#34;https://launchpad.net/&#34;&gt;Launchpad&lt;/a&gt; give it a try and let me know if it works or you have
any ideas to improve it.&lt;/p&gt;

&lt;p&gt;I should note it is bzr specific at this point as the reviews I do are primarily on bzr but it could be
extended with git support as needed.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Initial impressions of lxd</title>
      <link>http://backgroundprocess.com/infrastructure/lxd/</link>
      <pubDate>Wed, 14 Oct 2015 11:04:37 MDT</pubDate>
      <author>Tim Kuhlman</author>
      <guid>http://backgroundprocess.com/infrastructure/lxd/</guid>
      <description>&lt;p&gt;In the last couple of weeks I have been taking a bit of time here and there to explore &lt;a href=&#34;http://www.ubuntu.com/cloud/tools/lxd&#34;&gt;LXD&lt;/a&gt;.
LXD is a tool for managing system containers. As both LXD and Docker deal with containers in many ways there is quite a
bit of overlap but LXD is aiming for full isolated system containers where Docker is more focused on application containers. You can even run
Docker within an LXD image. I find it helpful to think of LXD as a replacement for virtual machines.&lt;/p&gt;

&lt;h3 id=&#34;lxd-features&#34;&gt;LXD Features&lt;/h3&gt;

&lt;p&gt;LXD is built upon &lt;a href=&#34;https://linuxcontainers.org/&#34;&gt;LXC&lt;/a&gt; which is impressively mature when compared to most of the container ecosystem. There are some
lacking features with LXC as pointed out at &lt;a href=&#34;https://www.stgraber.org/2015/04/21/lxd-getting-started/&#34;&gt;by the project lead&lt;/a&gt;.
LXC could benefit with some things that Docker brought to the table and LXD fills these gaps:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Container images and an easy way to share them.&lt;/li&gt;
&lt;li&gt;Simpler, easier to approach tools.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In addition to these features LXD is bringing to the table some new things, specifically:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Secure containers by default.&lt;/li&gt;
&lt;li&gt;Checkpoint/restore support to enable live migration&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;what-about-docker&#34;&gt;What about Docker&lt;/h3&gt;

&lt;p&gt;Thinking of LXD as a VM helps to clarify where it fits in a system workflow, it isn&amp;rsquo;t the entire picture. I have often thought of Docker containers
as a new style of highly specialized VMs. In fact many of the use cases where I have used Docker I have treated my container in many ways like a VM.
Though Docker is more focused on application containers and LXD on system containers there remains overlap between the two.&lt;/p&gt;

&lt;p&gt;Simple tools and most importantly easy to share and build upon images are primary reasons Docker became so popular.
This is what makes it easy to get started with Docker. Do you want to run Jenkins? With one command you can download the official image and have it running.
The ease of sharing images and building upon others is also what enables the emerging container devops deployment model. This model brings enough
advantages that has the potential to change how devops is done in the next few years.&lt;/p&gt;

&lt;p&gt;LXD is making some good progress with image sharing but it doesn&amp;rsquo;t go far enough to compete with Docker in this regard. Most notably the lack of a
public official repo with images you can build upon is missing from LXD.&lt;/p&gt;

&lt;p&gt;Though LXC is quite mature Docker has the lead as an app that wraps (or formerly wraps) LXC. With LXD it is still cumbersome to do some tasks, for
example a volume mount. Additionally there are little annoyances like the terminal columns/rows being set wrong when running bash in a container.
I expect much of this to be fixed as things mature but it is a sign that this is a new project.&lt;/p&gt;

&lt;p&gt;LXD does implement better default security in unprivileged containers, a nice feature to have. However Docker also continues to
improve in this area. LXD is also implementing live migration which I believe Docker is further behind on. This mostly seems to fit with the general
philosophy of a VM like system container versus application container.&lt;/p&gt;

&lt;h3 id=&#34;app-container-or-system-container&#34;&gt;App container or System container&lt;/h3&gt;

&lt;p&gt;In order to really think about when to use LXD and when to use Docker and how they overlap you have to explore the differences and use cases for
app container versus system containers. System containers act more like a VM with multiple processes and an init daemon. Applications containers
are leaner with no init and most often only a single service running though they aren&amp;rsquo;t limited to a single process.&lt;/p&gt;

&lt;p&gt;Today most deployed applications aren&amp;rsquo;t in any container and many companies are working on fundamentals of devops not implementing a container
based devops workflow. This migration is one area where system containers really shine, they are much easier to move an existing workflow and
applications to. In an application container without init suddenly something as basic as how you start your application changes.&lt;/p&gt;

&lt;p&gt;On the other hand a large porting of the advantages with containers are how they enable easier micro-services management and a new workflow. The
ability to not care how an image is built and to easily test the exact image that is deployed then to manage as a flexible pod with a tool like Kubernetes
are all advantages enabled by application containers.&lt;/p&gt;

&lt;p&gt;There are some use cases that won&amp;rsquo;t move to the new workflow. For example I don&amp;rsquo;t think I will ever again use a vm for development,
using a container brings the superiority of containers as well retaining the VM advantages of having a repeatable isolated dev environment. Given
the variety of tools used in development this is much better to do in a system container rather than an app container.&lt;/p&gt;

&lt;p&gt;Having all of the mature system tools at your disposal is one argument in favor of system containers. Many times saving devops time by having the
standard tools available beats the efficiency gain of a smaller image. In some cases I can easily see the initial move to containers be to a system
container with all the standard tools and later a move to a more tightly built application container.&lt;/p&gt;

&lt;p&gt;Regarding tooling it seems to me that container management tools should support both. They may have
their initial leanings simply as a way to focus development but ultimately I think system or app container is something to be decided by the use case
not by the tooling.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Docker for Messy Pets</title>
      <link>http://backgroundprocess.com/systems/desktop_docker/</link>
      <pubDate>Fri, 11 Sep 2015 21:12:37 MDT</pubDate>
      <author>Tim Kuhlman</author>
      <guid>http://backgroundprocess.com/systems/desktop_docker/</guid>
      <description>&lt;p&gt;The primary advantages of containers are realized when they are treated as the cattle of computing not pets. There are many
articles using that analogy to extol the advantages of containers as cattle or
&lt;a href=&#34;http://thenewstack.io/pets-and-cattle-symbolize-servers-so-what-does-that-make-containers-chickens/&#34;&gt;even as chickens&lt;/a&gt;.
However I have been recently rebuilding my Ubuntu Desktop and found containers can at times be great for pets also, most particularly the messy ones.&lt;/p&gt;

&lt;p&gt;I embarked down this route because of my sense of system cleanliness; too many apps I run excrete their dependencies all over my nice newly
installed system. I run a variety of apps that are not available either in the primary repo nor as a PPA or at least not with the version I need. If
I am not careful I can soon find myself juggling gems, eggs, wheels and jars all at the same time. Language specific package managers and tools like
virtualenv and bundler all help some but none are complete enough to take away all management so I still end up following many tools and cleaning
up the mess they leave behind.&lt;/p&gt;

&lt;p&gt;This is where Docker containers step in to save me. I simply need to build an image with the app and all its associated dependencies and wrap a
simple shell script around it. Now I can run my app while still maintaining a well organized system with no dependency hell, with no mess left behind
on my system. Instead of using various tools I now have one management tool to aid in running multiple versions or modifications of apps. In addition
I gain additional capabilities, most notably the ability to easily limit the resources an app can use.&lt;/p&gt;

&lt;p&gt;On Ubuntu, apt handles both dependency installation and cleanup very well and coupled with the availability of many
&lt;a href=&#34;https://help.launchpad.net/Packaging/PPA&#34;&gt;Personal Package Archives (ppa)&lt;/a&gt; the additional overhead of creating a container is not
worth it for these well behaved apps. This is particularly true as using apt enables automatic notification of security updates.
Nevertheless there are many apps or at least versions of the app I am using that aren&amp;rsquo;t available as a well behaved deb. These are the messy pets of
my workstation and I am much happier to have them in a container than to have them leaving a mess all over my desktop.&lt;/p&gt;

&lt;h3 id=&#34;implementation-details&#34;&gt;Implementation Details&lt;/h3&gt;

&lt;p&gt;I have begun a &lt;a href=&#34;https://github.com/tkuhlman/containers&#34;&gt;github repo&lt;/a&gt; with Dockerfiles and shell scripts I use for containers on my desktop. I will keep
expanding this as I add more apps which I use in this way. Here are some considerations as you put your messy pets in containers:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;In the wrapper scripts use Docker volumes to setup the appropriate directories, ie &lt;code&gt;-v /home/me/myfiles:/root/myfiles&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;GUI apps require some proper setup when running a container:

&lt;ul&gt;
&lt;li&gt;For X based apps first you must allow the app to connect to X then setup access to the display.&lt;/li&gt;
&lt;li&gt;To allow access to X I generally run &amp;lsquo;xhost local:&amp;rsquo; in the wrapper script. This has security
implications and shouldn&amp;rsquo;t be done on a shared system but for a system dedicated to a single user is reasonably safe.&lt;/li&gt;
&lt;li&gt;To setup access to the display export the Display variable with &lt;code&gt;-e DISPLAY=$DISPLAY&lt;/code&gt; and setup the volume with the x socket
&lt;code&gt;-v /tmp/.X11-unix:/tmp/.X11-unix&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;For advanced graphics with DRI things are a bit more complicated as you need the drivers you install in the image to match what the host uses.
After that I found you need to use the device flag for the Docker command to share in the dri device, ie &lt;code&gt;--device /dev/dri/card0:/dev/dri/card0&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;For pulseaudio, these flags to the Docker command work though possible could be distilled down to simpler steps:

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-v /dev/shm:/dev/shm&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-v /etc/machine-id:/etc/machine-id&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-v /run/user/$uid/pulse:/run/user/$uid/pulse&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-v /var/lib/dbus:/var/lib/dbus&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-v ~/.pulse:/home/$dockerUsername/.pulse&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Most docker images run apps as root within the container. Though this is generally fine it can be annoying for files in volume mounts to end up owned
as root. To work around this you can create a simplified user in the image matching your uid/gid and run apps as that user. All that is needed in
the images is an /etc/passwd entry, /etc/group entry and an appropriately owned home directory.&lt;/li&gt;
&lt;li&gt;Though this technique could work for any OS, it is most feasible where containers run natively. For those operating systems where containers are run in
a vm it is considerably more painful to run any desktop apps in containers. This is a good reason to run Linux on the desktop.&lt;/li&gt;
&lt;li&gt;The extra security of this approach was not my goal and I have not contemplated the implications much.
The app is far more isolated, but not perfectly so. Also an existing image
won&amp;rsquo;t update and break but is also more difficult to update for application security fixes. In short first glance you gain some security but there
are more aspects that need consideration.&lt;/li&gt;
&lt;li&gt;This technique is less annoying if your local user can run docker without sudo.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;

&lt;p&gt;I am by no means the first to try this and in fact was able to find many tips on how to accomplish desktop apps in containers. Here are the primary pages
I used as sources:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.jessfraz.com/post/docker-containers-on-the-desktop/&#34;&gt;https://blog.jessfraz.com/post/docker-containers-on-the-desktop/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://gernotklingler.com/blog/howto-get-hardware-accelerated-opengl-support-docker/&#34;&gt;http://gernotklingler.com/blog/howto-get-hardware-accelerated-opengl-support-docker/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://stackoverflow.com/questions/28985714/run-apps-using-audio-in-a-docker-container&#34;&gt;http://stackoverflow.com/questions/28985714/run-apps-using-audio-in-a-docker-container&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://fabiorehm.com/blog/2014/09/11/running-gui-apps-with-docker/&#34;&gt;http://fabiorehm.com/blog/2014/09/11/running-gui-apps-with-docker/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Hugo</title>
      <link>http://backgroundprocess.com/learning/hugo/</link>
      <pubDate>Wed, 12 Aug 2015 21:54:04 MDT</pubDate>
      <author>Tim Kuhlman</author>
      <guid>http://backgroundprocess.com/learning/hugo/</guid>
      <description>&lt;p&gt;I like static generated sites, simple, effective and secure. I love github pages as it gets the job done easily and well. Jekyll is a natural fit
with github pages and was a great way to start building a blog. However recently &lt;a href=&#34;http://gohugo.io/&#34;&gt;Hugo&lt;/a&gt; has caught my attention.&lt;/p&gt;

&lt;p&gt;I decided to switch to Hugo for a few different reasons:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;I like the clean directory layout better with Hugo.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;I want disqus, rss, tags, some easy social sharing links and google analytics. All of that is possible with Jekyll but some of these are much easier to setup with Hugo.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;It continues to have all the static site generation goodness and allows me to keep working with markdown and yaml.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Not that I have the greatest visual appeal to the blog now but a refreshed look is still welcome.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;On top of those reasons I am learning golang, which happens to be why I haven&amp;rsquo;t blogged in awhile but also adds some appeal to Hugo. The simple single binary installation
is great compared to dealing with ruby gems. That along with the ability to explore the code while I learn golang are really the reasons I first started looking at Hugo.&lt;/p&gt;

&lt;p&gt;It isn&amp;rsquo;t all great with Hugo, it does need a separate git repo which is a bit of a pain. Luckily the &lt;a href=&#34;http://gohugo.io/tutorials/github-pages-blog&#34;&gt;github pages tutorial&lt;/a&gt;
does a great job at explaining a few different git subrepo techniques and scripts to minimize the pain.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Vagrant Love</title>
      <link>http://backgroundprocess.com/infrastructure/vagrant/</link>
      <pubDate>Tue, 19 May 2015 21:56:28 MDT</pubDate>
      <author>Tim Kuhlman</author>
      <guid>http://backgroundprocess.com/infrastructure/vagrant/</guid>
      <description>&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://www.vagrantup.com/&#34;&gt;Vagrant&lt;/a&gt; is awesome!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Given its much deserved popularity this won&amp;rsquo;t surprise many. This isn&amp;rsquo;t even new, I&amp;rsquo;ve used it daily for quite awhile.
Recently while discussing use cases where Vagrant was an awesome fit I found myself wondering just why is it such a great tool?&lt;/p&gt;

&lt;p&gt;The best tools are those that reflect a deep understanding of the use cases and paradigms they are made for. Vagrant is actually
quite simple, roughly it just ties together some pre-built vms with the appropriate providers and configuration management tool. The key is that it does so
cleanly without adding baggage to the process.&lt;/p&gt;

&lt;p&gt;Another aspect that is important is that Vagrant chooses sane defaults but still allows configurability. The sane defaults combined with the clean design mean
that more often than not Vagrant makes building vm based environments far easier than any other way. This is probably what I love most about Vagrant, I can turn
around a clustered dev environment in under 5 minutes and even share it with my team with no extra work. This is orders of magnitude faster than other solutions.&lt;/p&gt;

&lt;p&gt;Building Vagrant based environments that fast takes good docs and familiarity with Vagrant. Vagrant has &lt;a href=&#34;https://docs.vagrantup.com/v2/&#34;&gt;great simple and clear docs&lt;/a&gt;
and the familiarity largely comes because Vagrant is versatile. The configurability of Vagrant allows it to have quite a bit of depth for those less than standard use cases.
This in turn means you come to know the tool and appreciate its simplicity and ease, which in turn makes it easier to use. All of this ultimately culminates in you
writing a blog post about Vagrant love.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
